{"label_file": "./data/tag.txt", "train_file": "./data/train.json", "dev_file": "./data/dev.json", "test_file": "./data/test.txt", "conf": "data/albert_tiny/config.json", "vocab": "data/albert_tiny/vocab.txt", "max_length": 50, "use_cuda": false, "gpu": 0, "batch_size": 400, "bert_path": "./data/bert", "albert_path": "data/albert_tiny/", "rnn_hidden": 200, "bert_embedding": 768, "albert_embedding": 312, "dropout1": 0.2, "dropout_ratio": 0.2, "rnn_layer": 2, "lr": 0.0001, "lr_decay": 1e-05, "weight_decay": 5e-05, "checkpoint": "result", "optim": "Adam", "load_model": false, "load_path": null, "base_epoch": 2, "attention_probs_dropout_prob": 0.0, "directionality": "bidi", "embedding_size": 128, "finetuning_task": "terry", "hidden_act": "gelu", "hidden_dropout_prob": 0.0, "hidden_size": 312, "initializer_range": 0.02, "intermediate_size": 1248, "layer_norm_eps": 1e-12, "ln_type": "postln", "max_position_embeddings": 512, "num_attention_heads": 12, "num_hidden_layers": 4, "num_labels": 3, "output_attentions": false, "output_hidden_states": false, "pooler_fc_size": 768, "pooler_num_attention_heads": 12, "pooler_num_fc_layers": 3, "pooler_size_per_head": 128, "pooler_type": "first_token_transform", "pruned_heads": {}, "share_type": "all", "torchscript": false, "type_vocab_size": 2, "vocab_size": 21128}